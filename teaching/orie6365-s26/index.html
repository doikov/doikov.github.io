<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ORIE 6365: Continuous Optimization: Algorithms and Complexity (Spring 2026)</title>
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 40px auto;
            padding: 0 20px;
            background-color: #fff;
        }
        h1, h2, h3 { color: #000; font-weight: 600; }
        a { color: #0066cc; text-decoration: none; }
        a:hover { text-decoration: underline; }
        table { width: 100%; border-collapse: collapse; margin: 20px 0; }
        th, td { text-align: left; padding: 10px; border-bottom: 1px solid #eee; }
        th { background-color: #f8f8f8; }
        .announcement { background: #fff9c4; padding: 15px; border-left: 5px solid #fbc02d; margin-bottom: 20px; }
        .course-meta { color: #666; }
        hr { border: 0; border-top: 1px solid #eee; margin: 30px 0; }
        code { background: #f4f4f4; padding: 2px 5px; border-radius: 3px; }
    </style>
</head>
<body>

    <center>
    <h2>ORIE 6365<h2>

    <h2>Continuous Optimization: Algorithms and Complexity</h2>

    <p class="course-meta">Spring 2026 | Cornell University | ORIE</p>
    </center>


    <p>
    Mon/Wed 10:10 AM – 11:25 AM <br/> 
    102 Upson Hall (Ithaca) and 397 Bloomberg Center (Cornell Tech)
    </p>

    <div class="announcement">
        <strong>Latest News:</strong> Welcome to the Spring 2026 semester! <strong>Homework 0</strong> is now available, the submission deadline is January 31.
    </div>

    <h2>Instructor</h2>
    <p>
        <strong>Nikita Doikov</strong><br/>
        Assistant Professor, ORIE<br/>
        Email: nikita.doikov at cornell.edu<br/>
        Office: 218 Rhodes Hall<br/>
        Office hours: Tuesdays 11:00 AM - 12:00 PM, Thursdays 2:00 PM - 3:00 PM, and by appointment<br/>
    </p>



    <h2>Course Description</h2>
    <p>
        This is a graduate-level course on the theory and algorithms of continuous optimization. It prepares students for research in optimization theory and for developing advanced methods for applications in operations research, machine learning, and related domains. The main emphasis is on understanding different classes of optimization problems and their theoretical limitations. We will rigorously study convergence rates and lower bounds for first-order and second-order optimization methods on both convex and non-convex problems, establishing the range of their applicability. <a href="syllabus.pdf">Syllabus</a>
    </p>

    <hr>
    <h2>Homeworks</h2>

    Please use Gradescope to upload your homeworks.

    <table>
        <tbody>
            <tr>
                <td><a href="orie6365_homework_0.pdf">Homework 0</a></td>
                <td>Due on January 31</td>
            </tr>
        </tbody>
    </table>

    <h2>Schedule & Materials</h2>


    <table>
        <thead>
            <tr>
                <th>Date</th>
                <th>Topic</th>
                <th>Materials</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Jan 21</td>
                <td>Introduction. Complexity of Optimization Problems. Grid Search.</td>
                <td><a href="notes/lecture01_slides.pdf">Slides</a> | 
                    <a href="notes/lecture01_whiteboard.pdf">Whiteboard</a></td>
            </tr>
            <tr>
                <td>Jan 26</td>
                <td>Lower Bound for Global Optimization. Smooth Functions.</td>
                <td></td>
            </tr>
            <tr>
                <td>Jan 28</td>
                <td>Gradient Descent for Finding Stationary Points.</td>
                <td></td>
            </tr>
            <tr>
                <td>Feb 2</td>
                <td>TBA</td>
                <td></td>
            </tr>
        </tbody>
    </table>


    <h2>Literature</h2>

    There is no single required textbook. The following sources are recommended for primary reading, alongside the provided lecture materials:

    <ul>
    <li>
        Yurii Nesterov,
        <em>Lectures on Convex Optimization</em>, Springer, 2018. 
    </li>
    <li>
        Arkadi Nemirovski, 
        <em><a href="https://www2.isye.gatech.edu/~nemirovs/Lect_EMCO.pdf">
        Information-Based Complexity of Convex Programming</a></em> (Lecture Notes).

    </li>
    </ul>
    Additional sources:
    <ul>
    <li>
        Sébastien Bubeck,
        <em><a href="https://arxiv.org/pdf/1405.4980">Convex Optimization: Algorithms and Complexity</a></em>, 2015. 
    </li>
    <li>
        Nisheeth K. Vishnoi, 
        <em><a href="https://convex-optimization.github.io/">
        Algorithms for Convex Optimization</a></em>, 2020.
    </li>
    </ul>
    <hr/>

    <p style="font-size: 0.8em; color: #999; margin-top: 50px;">
        &copy; 2026 Nikita Doikov.
    </p>

</body>
</html>